# Charger la librairie
library(haven)
#Importation des packages
library(tidyverse)
#Importation des packages
library(flexdashboard)
library(reticulate)
install.packages("reticulate")
#Importation des packages
library(flexdashboard)
library(reticulate)
library(ggplot2)
library(dplyr)
library(readr)
library(tidyr)
# 1. RUN LE SCRIPT PYTHON
# On utilise reticulate pour importer ton package
surf_scrap <- import("surf_scrap")
# 1. RUN LE SCRIPT PYTHON
# On utilise reticulate pour importer le package
surf_scrap <- import("surf_scrap")
# 1. RUN LE SCRIPT PYTHON
# On utilise reticulate pour importer le package
surf_scrap <- import("surf_scrap")
reticulate::py_config()
reticulate::py_install(".", pip = TRUE)
reticulate::py_install(".", pip = TRUE)
# 1. RUN LE SCRIPT PYTHON
# On utilise reticulate pour importer le package
surf_scrap <- import("surf_scrap")
reticulate::py_install("requests", pip = TRUE)
reticulate::py_install("beautifulsoup4", pip = TRUE)
reticulate::py_install("pandas", pip = TRUE)
# Enfin, ré-installe ton propre package pour être sûr
reticulate::py_install(".", pip = TRUE)
# 1. RUN LE SCRIPT PYTHON
# On utilise reticulate pour importer le package
surf_scrap <- import("surf_scrap")
reticulate::py_last_error()
# 1. RUN LE SCRIPT PYTHON
# On utilise reticulate pour importer le package
surf_scrap <- import("surf_scrap")
reticulate::py_install("requests", pip = TRUE)
reticulate::py_install("beautifulsoup4", pip = TRUE)
reticulate::py_install("pandas", pip = TRUE)
# Ré-installation de ton package local
reticulate::py_install(".", pip = TRUE)
# Forcer R à chercher ton package dans le répertoire actuel
py_run_string("import sys; sys.path.append('.')")
# Importation du package
surf_scrap <- import("surf_scrap")
```{r setup, include=FALSE}
library(flexdashboard)
library(reticulate)
# 1. On déclare les dépendances Python nécessaires
# R va les installer automatiquement dans l'environnement éphémère
py_require(c("requests", "beautifulsoup4", "pandas"))
# 2. On déclare ton propre package (le point "." désigne le dossier actuel)
# Cela permet à R de trouver 'surf_scrap' localement
py_require(".")
# 3. Maintenant on peut importer
surf_scrap <- import("surf_scrap")
library(flexdashboard)
library(reticulate)
# 1. On déclare les dépendances Python nécessaires
# R va les installer automatiquement dans l'environnement éphémère
py_require(c("requests", "beautifulsoup4", "pandas"))
# 2. On déclare ton propre package (le point "." désigne le dossier actuel)
# Cela permet à R de trouver 'surf_scrap' localement
py_require(".")
# 3. Maintenant on peut importer
surf_scrap <- import("surf_scrap")
library(plotly)
library(ggplot2)
library(dplyr)
library(DT)
library(flexdashboard)
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
# 1. Configuration de l'environnement
# On demande à R d'ajouter le dossier actuel au chemin Python pour trouver 'surf_scrap'
py_run_string("import sys; import os; sys.path.append(os.getcwd())")
# 2. Importation de ta bibliothèque
tryCatch({
surf_lib <- import("surf_scrap")
message("✅ Bibliothèque surf_scrap chargée avec succès")
}, error = function(e) {
stop("❌ Impossible de trouver 'surf_scrap'. Vérifiez que vous êtes dans le bon dossier.")
})
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
# 1. Configuration de l'environnement
# On demande à R d'ajouter le dossier actuel au chemin Python pour trouver 'surf_scrap'
py_run_string("import sys; import os; sys.path.append(os.getcwd())")
# 2. Importation de ta bibliothèque
tryCatch({
surf_lib <- import("surf_scrap")
message("✅ Bibliothèque surf_scrap chargée avec succès")
}, error = function(e) {
stop("❌ Impossible de trouver 'surf_scrap'. Vérifiez que vous êtes dans le bon dossier.")
})
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
# 1. Configuration de l'environnement
py_run_string("import sys; import os; sys.path.append(os.getcwd())")
# 2. Importation de ta bibliothèque
tryCatch({
surf_lib <- import("surf_scrap")
message("✅ Bibliothèque surf_scrap chargée avec succès")
}, error = function(e) {
stop("❌possible de trouver 'surf_scrap'. Vérifiez que vous êtes dans le bon dossier.")
})
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
# 1. Configuration de l'environnement
py_run_string("import sys; import os; sys.path.append(os.getcwd())")
# 2. Importation de ta bibliothèque
tryCatch({
surf_lib <- import("surf_scrap")
message("✅ Bibliothèque surf_scrap chargée avec succès")
}, error = function(e) {
stop("❌possible de trouver 'surf_scrap'. Vérifiez que vous êtes dans le bon dossier.")
})
# Force R à utiliser le dossier où est enregistré le fichier .Rmd
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
# 1. Configuration de l'environnement
py_run_string("import sys; import os; sys.path.append(os.getcwd())")
# 2. Importation de ta bibliothèque
tryCatch({
surf_lib <- import("surf_scrap")
message("✅ Bibliothèque surf_scrap chargée avec succès")
}, error = function(e) {
stop("❌possible de trouver 'surf_scrap'. Vérifiez que vous êtes dans le bon dossier.")
})
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
# Force R à utiliser le dossier où est enregistré le fichier .Rmd
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
# 1. Configuration de l'environnement
py_run_string("import sys; import os; sys.path.append(os.getcwd())")
# 2. Importation de ta bibliothèque
tryCatch({
surf_lib <- import("surf_scrap")
message("✅ Bibliothèque surf_scrap chargée avec succès")
}, error = function(e) {
stop("❌possible de trouver 'surf_scrap'. Vérifiez que vous êtes dans le bon dossier.")
})
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
# Détecter automatiquement le dossier du script sans rstudioapi
# Cela fonctionne pendant le 'Knit'
root <- getwd()
# 1. Pointer Python vers la racine 'Partie1'
# On utilise normalizePath pour être sûr que Windows comprend le chemin
py_run_string(sprintf("import sys; sys.path.append(r'%s')", root))
# 2. Importation sécurisée
# On enlève le tryCatch pour voir la VRAIE erreur si ça échoue
# (souvent il manque une dépendance comme 'requests')
surf_lib <- import("surf_scrap")
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
# 1. Déclarer les dépendances nécessaires
# R va vérifier leur présence et les installer dans l'environnement de session
py_require(c("requests", "beautifulsoup4", "pandas"))
# 2. Déclarer ton package local (le point '.' désigne le dossier Partie1)
py_require(".")
# 3. Importer ta bibliothèque
surf_lib <- import("surf_scrap")
library(flexdashboard)
library(reticulate)
# Force R à utiliser l'environnement virtuel de ton projet VSCode
# On remonte d'un niveau (..) car ton Rmd est dans 'Partie1' et .venv est au-dessus
use_virtualenv("../.venv", required = TRUE)
library(flexdashboard)
library(reticulate)
# Force R à utiliser l'environnement virtuel de ton projet VSCode
# On remonte d'un niveau (..) car ton Rmd est dans 'Partie1' et .venv est au-dessus
use_virtualenv("../.venv", required = TRUE)
# Importation
surf_lib <- import("surf_scrap")
# 4. Exécuter le scraping
URL <- "[https://www.surf-report.com/meteo-surf/lacanau-s1043.html](https://www.surf-report.com/meteo-surf/lacanau-s1043.html)"
CSV_OUT <- "data_surf.csv"
surf_lib$scrape_surf_report(URL, output_csv_path = CSV_OUT)
# 4. Exécuter le scraping
# NETTOYEZ BIEN L'URL : elle doit être une simple chaîne de caractères
URL <- "https://www.surf-report.com/meteo-surf/lacanau-s1043.html"
CSV_OUT <- "data_surf.csv"
# Appel de la fonction Python
surf_lib$scrape_surf_report(URL, output_csv_path = CSV_OUT)
# 5. Charger les données pour R
data <- readr::read_csv(CSV_OUT)
# 3. Préparation des KPIs (Nettoyage des plages de données)
df_clean <- data %>%
# On sépare "5.0 - 7.6" pour faire la moyenne de la plage
separate(Waves_size, into = c("min_w", "max_w"), sep = " - ", remove = FALSE, convert = TRUE) %>%
mutate(
# Calcul de la taille moyenne de la vague pour ce créneau
Wave_Mean = (min_w + max_w) / 2,
# Nettoyage du vent (au cas où il y a du texte)
Wind_Speed_Num = as.numeric(gsub("[^0-9.]", "", Wind_speed)),
# Index pour l'ordre chronologique
Time_Idx = row_number()
)
# 3. Préparation des KPIs (Nettoyage des plages de données)
library(tidyverse)
df_clean <- data %>%
# On sépare "5.0 - 7.6" pour faire la moyenne de la plage
separate(Waves_size, into = c("min_w", "max_w"), sep = " - ", remove = FALSE, convert = TRUE) %>%
mutate(
# Calcul de la taille moyenne de la vague pour ce créneau
Wave_Mean = (min_w + max_w) / 2,
# Nettoyage du vent (au cas où il y a du texte)
Wind_Speed_Num = as.numeric(gsub("[^0-9.]", "", Wind_speed)),
# Index pour l'ordre chronologique
Time_Idx = row_number()
)
# 3. Préparation des KPIs (Nettoyage des plages de données)
library(tidyverse)
# 2. Préparation des données (Nettoyage pour KPIs)
df_clean <- data %>%
# On sépare "5.0 - 7.6" pour calculer la moyenne de la plage
separate(Waves_size, into = c("w_min", "w_max"), sep = " - ", convert = TRUE, remove = FALSE) %>%
mutate(
Wave_Mean = (w_min + w_max) / 2,
Wind_Speed_Num = as.numeric(gsub("[^0-9.]", "", Wind_speed)),
# Calcul du Score de Qualité (Consigne : <1m wave, <50km/h wind, Nord)
Is_North = grepl("Nord", Wind_direction),
Quality_Score = case_when(
Wave_Mean <= 1.0 & Wind_Speed_Num <= 50 & Is_North ~ 100,
Wave_Mean <= 2.0 & Wind_Speed_Num <= 60 ~ 60,
TRUE ~ 30
),
Time_Idx = row_number()
)
# Identification des moments clés
best_moment <- df_clean %>% arrange(desc(Quality_Score), desc(Wave_Mean)) %>% head(1)
highest_wave <- df_clean %>% arrange(desc(w_max)) %>% head(1)
# 3. Préparation des KPIs (Nettoyage des plages de données)
library(tidyverse)
# 2. Préparation des données (Nettoyage pour KPIs)
df_clean <- data %>%
# On sépare "5.0 - 7.6" pour calculer la moyenne de la plage
separate(Waves_size, into = c("w_min", "w_max"), sep = " - ", convert = TRUE, remove = FALSE) %>%
mutate(
Wave_Mean = (w_min + w_max) / 2,
Wind_Speed_Num = as.numeric(gsub("[^0-9.]", "", Wind_speed)),
# Calcul du Score de Qualité (Consigne : <1m wave, <50km/h wind, Nord)
Is_North = grepl("Nord", Wind_direction),
Quality_Score = case_when(
Wave_Mean <= 1.0 & Wind_Speed_Num <= 50 & Is_North ~ 100,
Wave_Mean <= 2.0 & Wind_Speed_Num <= 60 ~ 60,
TRUE ~ 30
),
Time_Idx = row_number()
)
# Identification des moments clés
best_moment <- df_clean %>% arrange(desc(Quality_Score), desc(Wave_Mean)) %>% head(1)
highest_wave <- df_clean %>% arrange(desc(w_max)) %>% head(1)
valueBox(
value = paste(best_moment$Day, "@", best_moment$Hour),
caption = "Meilleur moment pour pratiquer",
icon = "fa-star",
color = "success"
)
valueBox(
value = paste(highest_wave$w_max, "m"),
caption = paste("Prévue le", highest_wave$Day),
icon = "fa-arrows-alt-v",
color = "info"
)
gauge(best_moment$Quality_Score, min = 0, max = 100, symbol = '%', gaugeSectors(
success = c(80, 100), warning = c(40, 79), danger = c(0, 39)
))
ggplot(df_clean, aes(x = Time_Idx, y = Wave_Mean)) +
geom_area(fill = "#0077b6", alpha = 0.3) +
geom_line(color = "#0077b6", size = 1) +
theme_minimal() +
labs(x = "Chronologie des prévisions", y = "Taille Moyenne (m)")
ggplot(df_clean, aes(x = Time_Idx, y = Wind_Speed_Num)) +
geom_col(fill = "#90e0ef") +
theme_minimal() +
labs(x = "Chronologie des prévisions", y = "Vitesse (km/h)")
df %>%
select(Day, Hour, Waves_size, Wind_direction) %>%
kable()
df_clean %>%
select(Day, Hour, Waves_size, Wind_direction) %>%
kable()
library(flexdashboard)
library(reticulate)
library(knitr)
# Force R à utiliser l'environnement virtuel de ton projet VSCode
# On remonte d'un niveau (..) car ton Rmd est dans 'Partie1' et .venv est au-dessus
use_virtualenv("../.venv", required = TRUE)
# Importation
surf_lib <- import("surf_scrap")
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
# Force R à utiliser l'environnement virtuel de ton projet VSCode
# On remonte d'un niveau (..) car ton Rmd est dans 'Partie1' et .venv est au-dessus
use_virtualenv("../.venv", required = TRUE)
# Importation
surf_lib <- import("surf_scrap")
# 3. Préparation des KPIs (Nettoyage des plages de données)
library(tidyverse)
# 2. Préparation des données (Nettoyage pour KPIs)
df_clean <- data %>%
# On sépare "5.0 - 7.6" pour calculer la moyenne de la plage
separate(Waves_size, into = c("w_min", "w_max"), sep = " - ", convert = TRUE, remove = FALSE) %>%
mutate(
Wave_Mean = (w_min + w_max) / 2,
Wind_Speed_Num = as.numeric(gsub("[^0-9.]", "", Wind_speed)),
# Calcul du Score de Qualité (Consigne : <1m wave, <50km/h wind, Nord)
Is_North = grepl("Nord", Wind_direction),
Quality_Score = case_when(
Wave_Mean <= 1.0 & Wind_Speed_Num <= 50 & Is_North ~ 100,
Wave_Mean <= 2.0 & Wind_Speed_Num <= 60 ~ 60,
TRUE ~ 30
),
Time_Idx = row_number()
)
# Identification des moments clés
best_moment <- df_clean %>% arrange(desc(Quality_Score), desc(Wave_Mean)) %>% head(1)
highest_wave <- df_clean %>% arrange(desc(w_max)) %>% head(1)
valueBox(
value = paste(best_moment$Day, "@", best_moment$Hour),
caption = "Meilleur moment pour pratiquer",
icon = "fa-star",
color = "success"
)
valueBox(
value = paste(highest_wave$w_max, "m"),
caption = paste("Prévue le", highest_wave$Day),
icon = "fa-arrows-alt-v",
color = "info"
)
gauge(best_moment$Quality_Score, min = 0, max = 100, symbol = '%', gaugeSectors(
success = c(80, 100), warning = c(40, 79), danger = c(0, 39)
))
ggplot(df_clean, aes(x = Time_Idx, y = Wave_Mean)) +
geom_area(fill = "#0077b6", alpha = 0.3) +
geom_line(color = "#0077b6", size = 1) +
theme_minimal() +
labs(x = "Chronologie des prévisions", y = "Taille Moyenne (m)")
ggplot(df_clean, aes(x = Time_Idx, y = Wind_Speed_Num)) +
geom_col(fill = "#90e0ef") +
theme_minimal() +
labs(x = "Chronologie des prévisions", y = "Vitesse (km/h)")
data %>%
select(Day, Hour, Waves_size, Wind_direction) %>%
kable()
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
# Force R à utiliser l'environnement virtuel de ton projet VSCode
# On remonte d'un niveau (..) car ton Rmd est dans 'Partie1' et .venv est au-dessus
use_virtualenv("../.venv", required = TRUE)
# Importation
surf_lib <- import("surf_scrap")
# 3. Préparation des KPIs (Nettoyage des plages de données)
library(tidyverse)
# 2. Préparation des données (Nettoyage pour KPIs)
df_clean <- data %>%
# On sépare "5.0 - 7.6" pour calculer la moyenne de la plage
separate(Waves_size, into = c("w_min", "w_max"), sep = " - ", convert = TRUE, remove = FALSE) %>%
mutate(
Wave_Mean = (w_min + w_max) / 2,
Wind_Speed_Num = as.numeric(gsub("[^0-9.]", "", Wind_speed)),
# Calcul du Score de Qualité (Consigne : <1m wave, <50km/h wind, Nord)
Is_North = grepl("Nord", Wind_direction),
Quality_Score = case_when(
Wave_Mean <= 1.0 & Wind_Speed_Num <= 50 & Is_North ~ 100,
Wave_Mean <= 2.0 & Wind_Speed_Num <= 60 ~ 60,
TRUE ~ 30
),
Time_Idx = row_number()
)
# Identification des moments clés
best_moment <- df_clean %>% arrange(desc(Quality_Score), desc(Wave_Mean)) %>% head(1)
highest_wave <- df_clean %>% arrange(desc(w_max)) %>% head(1)
valueBox(
value = paste(best_moment$Day, "@", best_moment$Hour),
caption = "Meilleur moment pour pratiquer",
icon = "fa-star",
color = "success"
)
valueBox(
value = paste(highest_wave$w_max, "m"),
caption = paste("Prévue le", highest_wave$Day),
icon = "fa-arrows-alt-v",
color = "info"
)
gauge(best_moment$Quality_Score, min = 0, max = 100, symbol = '%', gaugeSectors(
success = c(80, 100), warning = c(40, 79), danger = c(0, 39)
))
ggplot(df_clean, aes(x = Time_Idx, y = Wave_Mean)) +
geom_area(fill = "#0077b6", alpha = 0.3) +
geom_line(color = "#0077b6", size = 1) +
theme_minimal() +
labs(x = "Chronologie des prévisions", y = "Taille Moyenne (m)")
ggplot(df_clean, aes(x = Time_Idx, y = Wind_Speed_Num)) +
geom_col(fill = "#90e0ef") +
theme_minimal() +
labs(x = "Chronologie des prévisions", y = "Vitesse (km/h)")
data %>%
select(Day, Hour, Waves_size, Wind_direction) %>%
kable()
library(flexdashboard)
library(reticulate)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
# Force R à utiliser l'environnement virtuel de ton projet VSCode
# On remonte d'un niveau (..) car ton Rmd est dans 'Partie1' et .venv est au-dessus
use_virtualenv("../.venv", required = TRUE)
# Importation
surf_lib <- import("surf_scrap")
# Votre code pour la valueBox du meilleur moment
valueBox(
value = paste(best_moment$Day, "@", best_moment$Hour),
caption = "Meilleur moment pour pratiquer",
icon = "fa-star",
color = "success"
)
# Votre code pour la jauge (gauge)
gauge(best_moment$Quality_Score, min = 0, max = 100, symbol = '%', gaugeSectors(
success = c(80, 100), warning = c(40, 79), danger = c(0, 39)
))
# Votre graphique ggplot pour les vagues
ggplot(df_clean, aes(x = Time_Idx, y = Wave_Mean)) +
geom_area(fill = "#0077b6", alpha = 0.3) +
geom_line(color = "#0077b6", size = 1) +
theme_minimal() +
labs(x = "Chronologie des prévisions", y = "Taille Moyenne (m)")
# Votre graphique ggplot pour le vent
ggplot(df_clean, aes(x = Time_Idx, y = Wind_Speed_Num)) +
geom_col(fill = "#90e0ef") +
theme_minimal() +
labs(x = "Chronologie des prévisions", y = "Vitesse (km/h)")
# Votre code : knitr::kable(df_table)
data %>%
select(Day, Hour, Waves_size, Wind_direction) %>%
kable()
install.packages("kableExtra")
